{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b2389ef-fce8-4130-841f-100a05d265ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import input_file_name\n",
    "\n",
    "conf = (SparkConf().setMaster(\"k8s://https://192.168.219.100:6443\") # Your master address name\n",
    "        .set(\"spark.kubernetes.container.image\", \"joron1827/pyspark:v2\") # Spark image name\n",
    "        .set(\"spark.driver.port\", \"2222\") # Needs to match svc\n",
    "        .set(\"spark.driver.blockManager.port\", \"7777\")\n",
    "        .set(\"spark.driver.host\", \"driver-service.jupyterhub.svc.cluster.local\") # Needs to match svc\n",
    "        .set(\"spark.driver.bindAddress\", \"0.0.0.0\")\n",
    "        .set(\"spark.kubernetes.namespace\", \"spark\")\n",
    "        .set(\"spark.kubernetes.authenticate.driver.serviceAccountName\", \"spark\")\n",
    "        .set(\"spark.kubernetes.authenticate.serviceAccountName\", \"spark\")\n",
    "        .set(\"spark.executor.instances\", \"8\")\n",
    "        .set(\"spark.kubernetes.container.image.pullPolicy\", \"IfNotPresent\")\n",
    "        .set(\"spark.app.name\", \"joronSpark\")\n",
    "        .set(\"spark.executor.cores\", \"2\")\n",
    "        .set(\"spark.executor.memory\", \"12g\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ddcdb70-c555-4e10-a255-09d00faa208b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.9/site-packages/pyspark/bin/load-spark-env.sh: line 68: ps: command not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/01 20:08:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n",
    "import time\n",
    "\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e684cc79-08e3-4970-8580-9a32f9946b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efcd89cd-5275-4cbf-b494-88a680a3d412",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+------------------------------------+----------+------------------------------+\n",
      "|  code|      date|                               title|New_Column|                        tokens|\n",
      "+------+----------+------------------------------------+----------+------------------------------+\n",
      "|015760|2022-05-30|    이리저리 아무리 생각을 해 보아도|         1|[이리저리, 아무리, 생각, 해...|\n",
      "|015760|2022-05-30|    이리저리 아무리 생각을 해 보아도|         1|[이리저리, 아무리, 생각, 해...|\n",
      "|015760|2022-05-30|                  최순실때 만 갔으니|         1|    [최, 순, 실때, 만, 갔으니]|\n",
      "|015760|2022-05-30|어디에도 전기요금 동결 이야기 없는데|         1|[에도, 전기요금, 동결, 이야...|\n",
      "|015760|2022-05-30|                    매출은 오르는데 |         1|          [매출, 은, 오르는데]|\n",
      "|015760|2022-05-30|                         당분간 하락|         1|                [당분간, 하락]|\n",
      "|015760|2022-05-30|         죄인이처럼 나라 망치지 말자|         1|  [죄인, 처럼, 나라, 망치, ...|\n",
      "|015760|2022-05-30|              공매도 배 증가전날대비|         1|[공매도, 배, 증가, 전날, 대비]|\n",
      "|015760|2022-05-30|                   오늘 용돈 받았다 |         1|          [오늘, 용돈, 받았다]|\n",
      "|015760|2022-05-30| 어차피 개미털려면 가두리양식이 최고|         1|[어차피, 개미, 털려면, 가두...|\n",
      "|015760|2022-05-30|                       한전 상폐해라|         1|          [한전, 상, 폐해, 라]|\n",
      "|015760|2022-05-30|                        신용군담보군|         1|          [신용, 군, 담보, 군]|\n",
      "|015760|2022-05-30| 초밥맨 코데즈컴바인 월 일 억 부동산|         1| [초밥, 맨, 코데즈, 컴바인,...|\n",
      "|015760|2022-05-30|                                부터|         1|                            []|\n",
      "|015760|2022-05-30|      전쟁이 나면 누가 죽창을 드는가|         1|  [전쟁, 나면, 누가, 죽창, ...|\n",
      "|015760|2022-05-30|                    돌아온 설사 타임|         1|                [돌아온, 타임]|\n",
      "|015760|2022-05-30|                           설사 타임|         1|                        [타임]|\n",
      "|015760|2022-05-30|한전없애고산자부와 군이 직접운용해라|         1| [한전, 없애고, 산자부, 군,...|\n",
      "|015760|2022-05-30|                         최근 쥴리가|         1|                  [최근, 쥴리]|\n",
      "|015760|2022-05-30|  삭제된 게시물의 답글우리 문재인...|         1|  [삭제, 된, 게시, 물의, 답...|\n",
      "+------+----------+------------------------------------+----------+------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "filtered_df = tokenized_df.filter((col(\"New_Column\") == 0) | (col(\"New_Column\") == 2))\n",
    "tokenized_df = filtered_df.withColumn(\"New_Column\", when(col(\"New_Column\") == 2, 1).otherwise(col(\"New_Column\")))\n",
    "\n",
    "tokenized_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a60afbb5-dc98-43b5-bcd8-a8764c55ebf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:=====================================================>   (17 + 1) / 18]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-------------------------------+----------+------------------------------+\n",
      "|  code|      date|                          title|New_Column|                        tokens|\n",
      "+------+----------+-------------------------------+----------+------------------------------+\n",
      "|027740|2019-05-07|                         조천억|         1|                      [조천억]|\n",
      "|007160|2017-12-27|                    니   니  니|         0|                  [니, 니, 니]|\n",
      "|066570|2020-04-13|                           매동|         1|                          [동]|\n",
      "|028050|2021-09-24|             숨겨놓고 조질나...|         1|  [숨겨놓고, 조질, 나게, 판다]|\n",
      "|026890|2018-10-29|                 공매도취재요청|         1|          [공매도, 취재, 요청]|\n",
      "|007570|2021-03-11|          문재인 대통령 께서...|         0|[문재인, 대통령, 께서, 수출...|\n",
      "|042670|2021-02-08|              반복해서 말해보니|         1|      [반복, 해서, 말, 해보니]|\n",
      "|002210|2018-09-12|           오늘 장분석   과 ...|         1|    [오늘, 장, 분석, 낼, 예측]|\n",
      "|002210|2018-08-31|       동성제약  장분석  입니다|         1|  [동성제약, 장, 분석, 입니다]|\n",
      "|009150|2020-03-24|                  삼성전자 만원|         0|                  [삼성, 만원]|\n",
      "|035720|2017-10-17|     카카오 장마감 시황 속보 ㅎ|         1|  [카카오, 장마, 감, 시, 황...|\n",
      "|180640|2019-04-18|         부대  차렸     한칼...|         1|  [부대, 차렸, 한칼, 우, 향...|\n",
      "|035720|2022-06-24|               손실 중     손실|         0|              [손실, 중, 손실]|\n",
      "|323410|2021-08-09|                  수익으로 매도|         1|                  [수익, 매도]|\n",
      "|017800|2019-04-11|              여지가 있다라는건|         1|          [여지, 있다라는, 건]|\n",
      "|006980|2019-06-12|          월드컵 한국 결승 진출|         1|    [월드컵, 한국, 결승, 진출]|\n",
      "|034220|2019-09-19|    이두마리가 게시판 쓰레기...|         1| [두, 마리, 게시판, 쓰레기,...|\n",
      "|900140|2023-04-13|      자이 네나라는 어디일까요 |         0|  [자이, 네나, 라는, 일까, 요]|\n",
      "|052690|2021-11-18|                           재업|         1|                        [재업]|\n",
      "|003090|2022-01-28|      지수 간만에 좀 올라주는디|         0|      [지수, 간만, 올라주는디]|\n",
      "+------+----------+-------------------------------+----------+------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tokenized_df = tokenized_df.dropDuplicates([\"title\",\"tokens\"])\n",
    "tokenized_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aaf8278a-5008-4c85-972f-e2c94ae7d24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "769381"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd1454f-fca1-447d-985c-55bcf9e763e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:===============================================>         (15 + 3) / 18]\r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Word2Vec\n",
    "'''\n",
    "먼저 HashingTF를 사용하여 토큰화된 데이터를 TF(Term Frequency) 벡터로 변환합니다.\n",
    "그런 다음 IDF를 사용하여 TF 벡터를 TF-IDF(Inverse Document Frequency) 벡터로 변환합니다.\n",
    "TF-IDF 벡터화된 데이터를 Word2Vec 모델에 입력으로 사용하여 학습시킵니다.\n",
    "\n",
    "이렇게 하면 TF-IDF와 Word2Vec을 조합하여 문맥과 단어의 의미를 모두 반영하는 워드 임베딩을 생성할 수 있습니다.\n",
    "옵션을 사용하는 것보다는 이러한 조합을 통해 원하는 기능을 구현할 수 있습니다.\n",
    "'''\n",
    "\n",
    "# TF-IDF 벡터화를 위한 단계\n",
    "hashingTF = HashingTF(inputCol=\"tokens\", outputCol=\"tf\")\n",
    "tf_features = hashingTF.transform(tokenized_df)\n",
    "\n",
    "idf = IDF(inputCol=\"tf\", outputCol=\"tfidf\")\n",
    "idf_model = idf.fit(tf_features)\n",
    "tfidf_features = idf_model.transform(tf_features)\n",
    "\n",
    "tfidf_features.show()\n",
    "\n",
    "idf_model.save(\"hdfs://192.168.219.121:9000/crawling_stock_text_merge/two_class_idf_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2022bc84-e8b0-43ce-94ef-a45cb81f0281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec 모델 정의 및 학습\n",
    "word2Vec = Word2Vec(vectorSize=100, inputCol=\"tokens\", outputCol=\"word2vec\")\n",
    "word2Vec_model = word2Vec.fit(tfidf_features)\n",
    "word2Vec_features = word2Vec_model.transform(tfidf_features)\n",
    "word2Vec_features.show()\n",
    "word2Vec_model.save(\"hdfs://192.168.219.121:9000/crawling_stock_text_merge/two_class_word2Vec_model\")\n",
    "\n",
    "save_path = \"hdfs://192.168.219.121:9000/crawling_stock_text_merge/two_class_text_vectorized.parquet\"\n",
    "\n",
    "word2Vec_features.write.parquet(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bc87f8c-bdd3-47e5-8607-d9bcc0c27b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-------------------------------+----------+-----------------------------+--------------------+--------------------+--------------------+\n",
      "|  code|      date|                          title|New_Column|                       tokens|                  tf|               tfidf|            word2vec|\n",
      "+------+----------+-------------------------------+----------+-----------------------------+--------------------+--------------------+--------------------+\n",
      "|035720|2017-09-26|                               |         1|                           []|      (262144,[],[])|      (262144,[],[])|         (100,[],[])|\n",
      "|003550|2022-03-16|                      주주에...|         0|   [주주, 원한, 잇는건, 가요]|(262144,[51217,78...|(262144,[51217,78...|[0.01652339892461...|\n",
      "|323410|2021-08-09|                           이이|         1|                       [이이]|(262144,[104757],...|(262144,[104757],...|[0.03197551518678...|\n",
      "|007700|2020-06-26|                        와 소름|         0|                       [소름]|(262144,[121178],...|(262144,[121178],...|[-0.0952121093869...|\n",
      "|007460|2020-11-25|                           전환|         1|                       [전환]|(262144,[166149],...|(262144,[166149],...|[-0.1265893280506...|\n",
      "|066570|2018-12-28|             마지막 거래일 매동|         0|           [마지막, 거래, 동]|(262144,[97891,12...|(262144,[97891,12...|[-0.3128598978122...|\n",
      "|006400|2021-01-28|                   삼성전기  등|         1|                 [삼성, 전기]|(262144,[43121,20...|(262144,[43121,20...|[0.09944011270999...|\n",
      "|068270|2020-10-05|               육개장 내오거라 |         0|       [육개장, 내, 오거, 라]|(262144,[60764,74...|(262144,[60764,74...|[0.19440088607370...|\n",
      "|095720|2019-07-10|       입찰 참여 확실시되고 ...|         0| [입찰, 참여, 확, 실시, 되...|(262144,[7578,135...|(262144,[7578,135...|[0.11630692619543...|\n",
      "|005930|2019-12-27|                    너두 기다려|         1|                 [두, 기다려]|(262144,[136803,2...|(262144,[136803,2...|[0.20550757646560...|\n",
      "|047810|2019-10-04|             년말 영업이익 폭증|         0|     [년말, 영업, 이익, 폭증]|(262144,[54114,78...|(262144,[54114,78...|[0.41924566030502...|\n",
      "|010580|2018-03-22|           놀자 오빠가 무리할게|         1|       [놀자, 오빠, 무리할게]|(262144,[26556,13...|(262144,[26556,13...|[0.00531056399146...|\n",
      "|002150|2019-01-22|    단독보도 스웨덴 에서회의...|         1|[단독, 보도, 스웨덴, 회의,...|(262144,[36552,40...|(262144,[36552,40...|[0.06814633003986...|\n",
      "|005930|2023-01-04|                 단타반복질고려|         0|       [단, 타, 반복, 질고려]|(262144,[91473,11...|(262144,[91473,11...|[0.09954914823174...|\n",
      "|011170|2019-05-03|         소리들 그만하고 즐겨라|         0|     [소리, 그만하고, 즐겨라]|(262144,[21648,26...|(262144,[21648,26...|[0.01513559650629...|\n",
      "|008700|2018-02-01|                        시간외 |         1|                         [외]|(262144,[218214],...|(262144,[218214],...|[-0.1454489082098...|\n",
      "|005930|2019-12-27|             쎄꼬랑 찰것 같은데|         1|     [쎄꼬, 랑, 찰것, 같은데]|(262144,[18958,50...|(262144,[18958,50...|[-0.0606460943818...|\n",
      "|010050|2019-11-14|            안씨  형ㅈ들 욕본다|         1|     [안씨, 형, ㅈ, 욕, 본다]|(262144,[22267,55...|(262144,[22267,55...|[0.00390367065556...|\n",
      "|018250|2018-06-18|           애경산업마감시황 속 |         1| [애경, 산업, 마감, 시, 황...|(262144,[26704,65...|(262144,[26704,65...|[-0.0338763503047...|\n",
      "|019170|2020-04-13|                             와|         1|                           []|      (262144,[],[])|      (262144,[],[])|         (100,[],[])|\n",
      "+------+----------+-------------------------------+----------+-----------------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"hdfs://192.168.219.121:9000/crawling_stock_text_merge/two_class_text_vectorized.parquet\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3828ae1c-efe8-4f73-8f13-1f6de195d449",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+\n",
      "|New_Column|prediction|         probability|\n",
      "+----------+----------+--------------------+\n",
      "|         1|       1.0|[0.38771389493341...|\n",
      "|         1|       1.0|[0.30762478700942...|\n",
      "|         1|       1.0|[0.29564924712820...|\n",
      "|         1|       1.0|[0.36427519530033...|\n",
      "|         1|       1.0|[0.32625469297149...|\n",
      "|         1|       1.0|[0.25081950628528...|\n",
      "|         1|       1.0|[0.34254753549562...|\n",
      "|         0|       1.0|[0.27334411151194...|\n",
      "|         0|       1.0|[0.39324331467579...|\n",
      "|         1|       1.0|[0.37901248233718...|\n",
      "|         1|       1.0|[0.33579695574205...|\n",
      "|         0|       1.0|[0.25930828593347...|\n",
      "|         0|       1.0|[0.39206421910840...|\n",
      "|         0|       1.0|[0.38697373511627...|\n",
      "|         0|       1.0|[0.37890035477195...|\n",
      "|         0|       1.0|[0.36482174196766...|\n",
      "|         0|       1.0|[0.37947296414590...|\n",
      "|         0|       1.0|[0.35479864220121...|\n",
      "|         1|       1.0|[0.39940664937266...|\n",
      "|         0|       1.0|[0.31309989184558...|\n",
      "+----------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 340:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+------------------------------------+----------+------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|  code|      date|                               title|New_Column|                        tokens|                  tf|               tfidf|            word2vec|            features|       rawPrediction|         probability|prediction|\n",
      "+------+----------+------------------------------------+----------+------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|000020|2020-06-12|   요기 고수가 어딧냐 ㄱ 초보들뿐...|         1|  [요기, 고수, 어딧, 냐, ㄱ...|(262144,[43344,77...|(262144,[43344,77...|[-0.0527202452596...|[-0.0527202452596...|[-0.4569319817812...|[0.38771389493341...|       1.0|\n",
      "|000020|2020-07-29|                   동화약품과 제테마|         1|              [동화약품, 테마]|(262144,[156516,1...|(262144,[156516,1...|[0.15325093083083...|[0.15325093083083...|[-0.8112472076362...|[0.30762478700942...|       1.0|\n",
      "|000020|2020-07-29|오늘 공시가 안떠도 우상향하면 좋겠다|         1|  [오늘, 공시, 안, 떠도, 우...|(262144,[1204,104...|(262144,[1204,104...|[0.10966609744355...|[0.10966609744355...|[-0.8681026848277...|[0.29564924712820...|       1.0|\n",
      "|000020|2020-07-29|오늘 화이자 제테마 관련인데 이정도면|         1| [오늘, 화이자, 테마, 관련,...|(262144,[43344,64...|(262144,[43344,64...|[0.17477953646864...|[0.17477953646864...|[-0.5568561596525...|[0.36427519530033...|       1.0|\n",
      "|000020|2020-08-10|         이번주에     부광  잡는다야|         1|          [주, 부광, 잡는다야]|(262144,[126062,1...|(262144,[126062,1...|[0.04743090107028...|[0.04743090107028...|[-0.7251738136291...|[0.32625469297149...|       1.0|\n",
      "|000020|2020-08-10|                    조용히 올라가자 |         1|            [조용히, 올라가자]|(262144,[102391,2...|(262144,[102391,2...|[0.10151316970586...|[0.10151316970586...|[-1.0942463520872...|[0.25081950628528...|       1.0|\n",
      "|000020|2020-08-10|         찐찐찐찐 찐이야 완전 찐이야|         1|   [찐, 찐, 찐, 찐, 찐이야,...|(262144,[134677,2...|(262144,[134677,2...|[-0.1195380261966...|[-0.1195380261966...|[-0.6519620262664...|[0.34254753549562...|       1.0|\n",
      "|000020|2020-10-30|   하한가 하한가 신나는 노랭 나도...|         0| [한가, 한가, 신나는, 노랭,...|(262144,[25535,53...|(262144,[25535,53...|[0.17908089288643...|[0.17908089288643...|[-0.9777215514756...|[0.27334411151194...|       1.0|\n",
      "|000020|2021-02-04|              공매도 치는 개관들이게|         0|  [공매도, 치는, 개관, 들이게]|(262144,[10185,23...|(262144,[10185,23...|[-0.1664010882377...|[-0.1664010882377...|[-0.4336993211924...|[0.39324331467579...|       1.0|\n",
      "|000020|2021-04-28|  삭제된 게시물의 답글삭제된 게시...|         1|  [삭제, 된, 게시, 물의, 답...|(262144,[73741,12...|(262144,[73741,12...|[0.18557456860850...|[0.18557456860850...|[-0.4937418418828...|[0.37901248233718...|       1.0|\n",
      "|000020|2021-04-28|외인 나가려는 순간 주포가 쳐들어온다|         1|[외인, 나가려는, 순간, 주포...|(262144,[5402,966...|(262144,[5402,966...|[-0.0297225018342...|[-0.0297225018342...|[-0.6820812133628...|[0.33579695574205...|       1.0|\n",
      "|000020|2021-11-15|                              먼일이|         0|                        [먼일]|(262144,[37767],[...|(262144,[37767],[...|[0.11389966309070...|[0.11389966309070...|[-1.0495668512895...|[0.25930828593347...|       1.0|\n",
      "|000020|2021-11-15| 신규확진 일째 명대 수도권 병상 비상|         0|  [신규, 확진, 째, 명대, 수...|(262144,[57429,63...|(262144,[57429,63...|[0.02537338116339...|[0.02537338116339...|[-0.4386436022251...|[0.39206421910840...|       1.0|\n",
      "|000020|2021-11-15| 읽어주세요 강성주주 여러분들께 고함|         0|[읽어주세요, 강성, 주주, 께...|(262144,[21139,62...|(262144,[21139,62...|[-0.2070498961955...|[-0.2070498961955...|[-0.4600509586743...|[0.38697373511627...|       1.0|\n",
      "|000020|2021-11-25|   이거는 도대체 오르는 날이 없어...|         0|  [거, 는, 도대체, 오르는, ...|(262144,[36552,91...|(262144,[36552,91...|[0.17674064310267...|[0.17674064310267...|[-0.4942182740207...|[0.37890035477195...|       1.0|\n",
      "|000020|2022-04-13|                         쥐꼬리 망초|         0|                [쥐꼬리, 망초]|(262144,[34348,43...|(262144,[34348,43...|[-0.0032376507297...|[-0.0032376507297...|[-0.5544968246923...|[0.36482174196766...|       1.0|\n",
      "|000020|2022-05-13|  북한에 감기약 보내야 하는거 아닌가|         0|  [북한, 감기, 약, 보내야, ...|(262144,[52339,99...|(262144,[52339,99...|[0.14478707313537...|[0.14478707313537...|[-0.4917858211980...|[0.37947296414590...|       1.0|\n",
      "|000040|2019-12-11|    연상 갈 수 있는 분명한 방법이...|         0|  [연상, 갈, 수, 있는, 분명...|(262144,[42636,84...|(262144,[42636,84...|[0.02899918785052...|[0.02899918785052...|[-0.5980120272239...|[0.35479864220121...|       1.0|\n",
      "|000040|2020-12-04|   수도권역대급  환자발생  배달오...|         1|  [수도권, 역대, 급, 환자, ...|(262144,[16075,35...|(262144,[16075,35...|[0.10853295607699...|[0.10853295607699...|[-0.4079380150239...|[0.39940664937266...|       1.0|\n",
      "|000040|2021-02-05|       공시내용 호재거리 별로 없고마|         0|  [공시, 내용, 호재, 거리, ...|(262144,[1204,947...|(262144,[1204,947...|[0.18924420544256...|[0.18924420544256...|[-0.7856665957713...|[0.31309989184558...|       1.0|\n",
      "+------+----------+------------------------------------+----------+------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Area Under ROC: 0.5911524391164069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# 학습 데이터와 테스트 데이터 분할 (70% 학습, 30% 테스트)\n",
    "train_data, test_data = df.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "# 로지스틱 회귀 모델 초기화\n",
    "lr = LogisticRegression(labelCol=\"New_Column\", featuresCol=\"word2vec\")\n",
    "\n",
    "# 모델 학습\n",
    "model = lr.fit(train_data)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# 예측 결과 확인\n",
    "predictions.select(\"New_Column\", \"prediction\", \"probability\").show()\n",
    "\n",
    "# 이진 분류 평가 지표 계산 (예시로는 Area Under ROC를 사용)\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"New_Column\")\n",
    "auc = evaluator.evaluate(predictions)\n",
    "\n",
    "predictions.show()\n",
    "print(\"Area Under ROC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10939afe-b962-41bb-a5c8-a013cf7d169c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 249:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+\n",
      "|New_Column|prediction|         probability|\n",
      "+----------+----------+--------------------+\n",
      "|         1|       1.0|[0.34390539966221...|\n",
      "|         1|       1.0|[0.35685039350669...|\n",
      "|         1|       1.0|[0.33849279022470...|\n",
      "|         1|       1.0|[0.34827823429516...|\n",
      "|         1|       1.0|[0.34506017959558...|\n",
      "|         1|       1.0|[0.34755194720732...|\n",
      "|         1|       1.0|[0.34110266046455...|\n",
      "|         0|       1.0|[0.34452171239640...|\n",
      "|         0|       1.0|[0.34762383652253...|\n",
      "|         1|       1.0|[0.34807300949824...|\n",
      "|         1|       1.0|[0.34419556936462...|\n",
      "|         0|       1.0|[0.33490293486148...|\n",
      "|         0|       1.0|[0.34934310765584...|\n",
      "|         0|       1.0|[0.34964418771949...|\n",
      "|         0|       1.0|[0.33852623756317...|\n",
      "|         0|       1.0|[0.35042475481537...|\n",
      "|         0|       1.0|[0.34761696782093...|\n",
      "|         0|       1.0|[0.34572773519702...|\n",
      "|         1|       1.0|[0.35475344484117...|\n",
      "|         0|       1.0|[0.34789772288779...|\n",
      "+----------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# RandomForestClassifier 모델을 생성합니다\n",
    "rf = RandomForestClassifier(labelCol=\"New_Column\", featuresCol=\"word2vec\")\n",
    "\n",
    "# 파이프라인을 생성합니다\n",
    "pipeline = Pipeline(stages=[rf])\n",
    "\n",
    "# 모델을 학습시킵니다\n",
    "model = pipeline.fit(train_data)  # trainData는 학습에 사용할 데이터 프레임입니다\n",
    "\n",
    "# 학습된 모델을 사용하여 예측을 수행합니다\n",
    "predictions = model.transform(test_data)  # testData는 예측에 사용할 데이터 프레임입니다\n",
    "\n",
    "# 예측 결과 확인\n",
    "predictions.select(\"New_Column\", \"prediction\", \"probability\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "292f80c2-5e54-4fb9-bbe9-d17a2ec61155",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 199:================================================>      (15 + 2) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6551456158935797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# MulticlassClassificationEvaluator를 사용하여 정확도를 계산합니다\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"New_Column\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09016051-99c8-4ab6-945a-e9aa36e8f06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 205:==========================================>            (13 + 4) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.42921577802457783\n",
      "Recall: 0.6551456158935797\n",
      "F1 Score: 0.5186441288343719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# MulticlassClassificationEvaluator를 사용하여 정밀도, 재현율, F1 스코어를 계산합니다\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"New_Column\", predictionCol=\"prediction\")\n",
    "\n",
    "# 정밀도 계산\n",
    "precision = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
    "\n",
    "# 재현율 계산\n",
    "recall = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedRecall\"})\n",
    "\n",
    "# F1 스코어 계산\n",
    "f1_score = evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"})\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d063a10f-83ff-4072-95b4-88f17d2b4667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 230:===================================================>   (16 + 1) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6551456158935797\n",
      "Precision: 0.42921577802457783\n",
      "Recall: 0.6551456158935797\n",
      "F1 Score: 0.5186441288343719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# 의사결정트리 모델 생성\n",
    "dt = DecisionTreeClassifier(labelCol=\"New_Column\", featuresCol=\"word2vec\")\n",
    "\n",
    "# 모델 훈련\n",
    "dt_model = dt.fit(train_data)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "dt_predictions = dt_model.transform(test_data)\n",
    "\n",
    "# 평가 지표 계산을 위한 MulticlassClassificationEvaluator 생성\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"New_Column\", predictionCol=\"prediction\")\n",
    "\n",
    "# 정확도 계산\n",
    "accuracy = evaluator.evaluate(dt_predictions, {evaluator.metricName: \"accuracy\"})\n",
    "\n",
    "# 정밀도 계산\n",
    "precision = evaluator.evaluate(dt_predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
    "\n",
    "# 재현율 계산\n",
    "recall = evaluator.evaluate(dt_predictions, {evaluator.metricName: \"weightedRecall\"})\n",
    "\n",
    "# F1 스코어 계산\n",
    "f1_score = evaluator.evaluate(dt_predictions, {evaluator.metricName: \"f1\"})\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812ad806-3ce8-471e-a3fb-ee0fd930fd3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
